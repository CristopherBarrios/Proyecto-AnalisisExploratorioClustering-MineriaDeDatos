---
title: "Resultados del proyecto"
author: "Josué Sagastume, Cristopher Barrios, Diego Ruiz"
date: "23/5/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r echo=FALSE}
defaultW <- getOption("warn")
options(warn = -1)
```

```{r, echo=FALSE, include=FALSE}
library(cluster) #Para calcular la silueta
library(e1071)#para cmeans
library(mclust) #mixtures of gaussians
library(fpc) #para hacer el plotcluster
library(NbClust) #Para determinar el n?mero de clusters ?ptimo
library(factoextra) #Para hacer gr?ficos bonitos de clustering
library(rpart)
library(caret)
library(tree)
library(rpart.plot)
library(ggplot2)
library(randomForest)
library(tidyverse)
library(DataExplorer)
library(reshape2)
library(grid)
library(corrplot)
```

```{r echo=FALSE}
load("dataframe.RData")
```

```{r echo=FALSE}
divorciosDFdepar <- divorcios_anio_mes_departamento
```

## Resultados del proyecto

### 1. Elección de variable respuesta

Para poder llegar más a fondo sobre las causas de divorcio en Guatemala y en qué departamentos tiene una cantidad más alta de divorcios, se decidió utilizar machine learning para poder predecir si dadas ciertas características la demanda será alta, media o baja.

Para poder estudiar categóricamente, se agregará una variable adicional clasificativa en el dataset para llevar a cabo la predicción. En este caso, se separó en 3 grupos.

### 2. Conjuntos de entrenamiento y prueba

Para este caso, se utilizó del conjunto total de datos, el 70% para entrenamiento y 30% para pruebas, de este modo los datos estarán equilibrados para poder realizar buenas predicciones.

### 3. Algoritmos utilizados

Para poder llegar a la solución de este problema, se aplicarán 3 algoritmos. El primero es de clustering con k-means, este para poder encontrar la cantidad óptima de grupos a utilizar para la variable respuesta categórica. El segundo algoritmo a utilizar es el de Naive Bayes, pues es un algoritmo de clasificación. Este nos brinda la ventaja de que, por su estructura, es muy asertivo, es rápido y también escalable. También se utilizó el algoritmo de Árboles de decisión, pues también clasifican la información de manera que, como resultado, se genere un modelo de en forma de árbol. La ventaja de este algoritmo, es que también puede ser utilizado para predecir datos, ayudándonos a resolver el problema en cuestión. 

#### Grafica de codos de divorcios por departamento por mes
``` {r echo=FALSE}
datosDepar <- select(divorciosDFdepar,Total,Guatemala,El.Progreso,Sacatepequez,Chimaltenango,
                Escuintla,Santa.Rosa,Solola,Totonicapan,Quetzaltenango,Suchitepequez,
                Retalhuleu,San.Marcos,Huehuetenango,Quiche,Baja.Verapaz,Alta.Verapaz,
                Peten,Izabal,Zacapa,Chiquimula,Jalapa,Jutiapa)

scaledDataDepar <- as.matrix(scale(datosDepar))
k.max  <- 15
wssDepar <- sapply(1:k.max, 
              function(k){kmeans(datosDepar,k,iter.max = 100 )$tot.withinss})
plot(1:k.max,wssDepar,
        type="b",
        xlab="No. clusters",
        ylab="No. Suma de cuadrados")
```


#### Numero de Clusters (Divorcios por departamento por mes)
``` {r echo=FALSE}
kmDepar<-kmeans(scaledDataDepar, 3, iter.max = 100)
fviz_cluster(kmDepar, data = scaledDataDepar, frame.type = "convex")
```

#### Aplicacion de clusters a Data Inicial y Separacion de grupos
``` {r echo=FALSE}
set.seed(314)
divorciosDFdepar$Categoria <- kmDepar$cluster

groupOne <- divorciosDFdepar[divorciosDFdepar$Categoria == "Demanda baja",]
groupTwo <- divorciosDFdepar[divorciosDFdepar$Categoria == "Demanda media",]
groupThree <- divorciosDFdepar[divorciosDFdepar$Categoria == "Demanda alta",]
```


#### Grafica de Silueta (Divorcios por departamento por mes)
``` {r echo=FALSE}
dis = dist(scaledDataDepar)^2
sil = silhouette(kmDepar$cluster,dis)
dev.new(width=5,height=8,noRStudioGD = TRUE,unit="in")

silkm<-silhouette(kmDepar$cluster,dist(divorciosDFdepar[,1:22])^2)
mean(2*silkm[,3]) #0.55, no es la mejor particiÃ³n pero no estÃ¡ mal

```

#### Aplicacion de Naive Bayes (Divorcios por departamento por mes)
``` {r echo=FALSE}
porcentaje <- 0.7

divorciosDFdepar1 <- divorciosDFdepar[,3:25]
divorciosDFdepar1$Categoria <- ifelse(divorciosDFdepar1$Categoria == 1, "Demanda baja", ifelse(divorciosDFdepar1$Categoria == 2, "Demanda media", ifelse(divorciosDFdepar1$Categoria == 3, "Demanda alta", 0)))

divorciosDFdepar1$Categoria <- factor(divorciosDFdepar1$Categoria)                                

corteDepar <- sample(nrow(divorciosDFdepar1),nrow(divorciosDFdepar1)*porcentaje)
trainDepar<-divorciosDFdepar1[corteDepar,]
testDepar<-divorciosDFdepar1[-corteDepar,]

modeloDepar<-naiveBayes(trainDepar$Categoria~.,data=trainDepar)

predBayesDepar<-predict(modeloDepar, newdata = testDepar[,1:22])

cmDepar <- caret::confusionMatrix(predBayesDepar, testDepar$Categoria)

ctDepar <- trainControl(method = "cv",trainDepar[,1:22],number=10, verboseIter=T)
modeloCaretDepar <- train(Categoria~.,data=trainDepar,method="nb",trControl = ctDepar)
prediccionCaretDepar <- predict(modeloCaretDepar,newdata = testDepar[,1:22])
caret::confusionMatrix(prediccionCaretDepar,testDepar$Categoria)
```

#### Aplicacion de Arboles de Decision (Divorcios por departamento por mes)
```{r echo=FALSE}
corteDepar <- sample(nrow(divorciosDFdepar1),nrow(divorciosDFdepar1)*porcentaje)
trainDepar<-divorciosDFdepar1[corteDepar,]
testDepar<-divorciosDFdepar1[-corteDepar,]

arbolModeloDepar <- rpart(Categoria~., divorciosDFdepar1, method = "class")
rpart.plot(arbolModeloDepar)

#arbolModelo<-rpart(Species~.,datos,method = "class")
#rpart.plot(arbolModelo)

View(testDepar)
prediccion <- predict(arbolModeloDepar, newdata = testDepar[,1:22])

#prediccion <- predict(dt_model, newdata = test[1:4])

columnaMasAlta <- apply(prediccion, 1, function(x) colnames(prediccion)[which.max(x)])
columnaMasAlta
testDepar$prediccion <- columnaMasAlta
View(testDepar)
#Apply: Para cada fila, determina el nombre de la columna del valor mÃ¡ximo entre los tres valores de una fila
#columnaMasAlta<-apply(prediccion, 1, function(x) colnames(prediccion)[which.max(x)])
#test$prediccion<-columnaMasAlta #Se le aÃ±ade al grupo de prueba el valor de la predicciÃ³n


cfm <- confusionMatrix(as.factor(testDepar$prediccion),testDepar$Categoria)
cfm


modeloRF1 <- randomForest(Categoria~.,data=trainDepar)
prediccionRF1 <- predict(modeloRF1,newdata = testDepar[,1:22])
testCompleto<-testDepar
testCompleto$predRF<-prediccionRF1
cfmRandomForest <- confusionMatrix(testCompleto$predRF, testCompleto$Categoria)
cfmRandomForest
```



### 3. Algoritmos utilizados


### 4. Resultados


#### 4.1 Predicción 
 
 
#### 4.2 Matrices de confusión

```{r echo=FALSE, include=FALSE}
options(warn = defaultW)
```

